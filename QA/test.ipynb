{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_DIR = '/root/Dataset/COSMOS/cosmos_anns_acm/acm_anns/'\n",
    "CONTEXT_DIR = '/root/Dataset/COSMOS/context/Context_EL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from QA import answer\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "from itertools import groupby\n",
    "import re\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_id(filename: str) -> int:\n",
    "    return int(re.search('([0-9]+)_[0-9]+\\.txt', filename).group(1))\n",
    "\n",
    "context_files = [join(CONTEXT_DIR, file) for file in listdir(CONTEXT_DIR) if isfile(join(CONTEXT_DIR, file))]\n",
    "context_files = sorted(context_files, key=get_image_id)\n",
    "\n",
    "context_files_grouped_by_image_id = {key: list(val) for key, val in groupby(context_files, key = get_image_id)}\n",
    "\n",
    "test_data = pd.read_json(join(ANNOTATION_DIR, 'test_data.json'), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['context_filename'] = pd.DataFrame([context_files_grouped_by_image_id]).T\n",
    "test_data['context_filename'] = [ [] if x is np.NaN else x for x in test_data['context_filename'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    context_filename = row.context_filename\n",
    "    answers = []\n",
    "    for filename in context_filename:\n",
    "        with open(filename, 'r', encoding='utf8') as ifile:\n",
    "            content = json.load(ifile)\n",
    "        context = content['context']\n",
    "        if context == '':\n",
    "            continue\n",
    "        context = ' '.join(context.split('\\n'))\n",
    "        answers.append(answer(context, row.caption1, row.caption2))\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:04<00:00,  8.02it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data['answers'] = test_data.progress_apply(process, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('./df_answer_EL.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_local_path</th>\n",
       "      <th>caption1</th>\n",
       "      <th>caption2</th>\n",
       "      <th>context_label</th>\n",
       "      <th>article_url</th>\n",
       "      <th>maskrcnn_bboxes</th>\n",
       "      <th>caption1_modified</th>\n",
       "      <th>caption1_entities</th>\n",
       "      <th>caption2_modified</th>\n",
       "      <th>caption2_entities</th>\n",
       "      <th>bert_base_score</th>\n",
       "      <th>bert_large_score</th>\n",
       "      <th>context_filename</th>\n",
       "      <th>answers</th>\n",
       "      <th>sim</th>\n",
       "      <th>pred</th>\n",
       "      <th>final_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>public_test_mmsys/0.jpg</td>\n",
       "      <td>Julian Castro at his announcement in San Anton...</td>\n",
       "      <td>Julian Castro at his announcement in San Anton...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.nytimes.com/2019/06/13/us/politics...</td>\n",
       "      <td>[[389.9706726074219, 72.9228744506836, 505.056...</td>\n",
       "      <td>PERSON at his announcement in GPE, GPE, on DAT...</td>\n",
       "      <td>[['Julian Castro', 'PERSON'], ['San Antonio', ...</td>\n",
       "      <td>PERSON at his announcement in GPE, GPE, on DATE.</td>\n",
       "      <td>[['Julian Castro', 'PERSON'], ['San Antonio', ...</td>\n",
       "      <td>0.576995</td>\n",
       "      <td>0.601183</td>\n",
       "      <td>['/root/Dataset/COSMOS/context/Context_EL/0_1....</td>\n",
       "      <td>[('lightweight” without the experience needed ...</td>\n",
       "      <td>[0.06486875, 0.99999994]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>public_test_mmsys/1.jpg</td>\n",
       "      <td>Supporters of Tanzania's ruling Chama Cha Mapi...</td>\n",
       "      <td>A person sits on a truck as supporters of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.bbc.com/news/world-africa-54828934</td>\n",
       "      <td>[[389.6280517578125, 8.949727058410645, 609.61...</td>\n",
       "      <td>Supporters of GPE's ruling ORG party come out ...</td>\n",
       "      <td>[['Tanzania', 'GPE'], ['Chama Cha Mapinduzi', ...</td>\n",
       "      <td>A person sits on a truck as supporters of the ...</td>\n",
       "      <td>[['Chama Cha Mapinduzi', 'PERSON'], ['Revoluti...</td>\n",
       "      <td>0.541939</td>\n",
       "      <td>0.729243</td>\n",
       "      <td>['/root/Dataset/COSMOS/context/Context_EL/1_8....</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>public_test_mmsys/2.jpg</td>\n",
       "      <td>53,000 dead people turned up on the state’s vo...</td>\n",
       "      <td>These social media posts did not link to a rec...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.snopes.com/fact-check/53000-dead-f...</td>\n",
       "      <td>[[0.0, 14.214579582214355, 326.70501708984375,...</td>\n",
       "      <td>CARDINAL dead people turned up on the state’s ...</td>\n",
       "      <td>[['53,000', 'CARDINAL'], ['November 2018', 'DA...</td>\n",
       "      <td>These social media posts did not link to a rec...</td>\n",
       "      <td>[['Florida', 'GPE'], ['November 2018', 'DATE']...</td>\n",
       "      <td>0.234810</td>\n",
       "      <td>0.307628</td>\n",
       "      <td>['/root/Dataset/COSMOS/context/Context_EL/2_1....</td>\n",
       "      <td>[('an army of internet trolls', \"53,000 dead p...</td>\n",
       "      <td>[0.025132587, 0.07283948, 0.026980357, 0.10170...</td>\n",
       "      <td>[True, True, True, True, True]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0           img_local_path  \\\n",
       "0             0           0  public_test_mmsys/0.jpg   \n",
       "1             1           1  public_test_mmsys/1.jpg   \n",
       "2             2           2  public_test_mmsys/2.jpg   \n",
       "\n",
       "                                            caption1  \\\n",
       "0  Julian Castro at his announcement in San Anton...   \n",
       "1  Supporters of Tanzania's ruling Chama Cha Mapi...   \n",
       "2  53,000 dead people turned up on the state’s vo...   \n",
       "\n",
       "                                            caption2  context_label  \\\n",
       "0  Julian Castro at his announcement in San Anton...              0   \n",
       "1  A person sits on a truck as supporters of the ...              0   \n",
       "2  These social media posts did not link to a rec...              1   \n",
       "\n",
       "                                         article_url  \\\n",
       "0  https://www.nytimes.com/2019/06/13/us/politics...   \n",
       "1     https://www.bbc.com/news/world-africa-54828934   \n",
       "2  https://www.snopes.com/fact-check/53000-dead-f...   \n",
       "\n",
       "                                     maskrcnn_bboxes  \\\n",
       "0  [[389.9706726074219, 72.9228744506836, 505.056...   \n",
       "1  [[389.6280517578125, 8.949727058410645, 609.61...   \n",
       "2  [[0.0, 14.214579582214355, 326.70501708984375,...   \n",
       "\n",
       "                                   caption1_modified  \\\n",
       "0  PERSON at his announcement in GPE, GPE, on DAT...   \n",
       "1  Supporters of GPE's ruling ORG party come out ...   \n",
       "2  CARDINAL dead people turned up on the state’s ...   \n",
       "\n",
       "                                   caption1_entities  \\\n",
       "0  [['Julian Castro', 'PERSON'], ['San Antonio', ...   \n",
       "1  [['Tanzania', 'GPE'], ['Chama Cha Mapinduzi', ...   \n",
       "2  [['53,000', 'CARDINAL'], ['November 2018', 'DA...   \n",
       "\n",
       "                                   caption2_modified  \\\n",
       "0   PERSON at his announcement in GPE, GPE, on DATE.   \n",
       "1  A person sits on a truck as supporters of the ...   \n",
       "2  These social media posts did not link to a rec...   \n",
       "\n",
       "                                   caption2_entities  bert_base_score  \\\n",
       "0  [['Julian Castro', 'PERSON'], ['San Antonio', ...         0.576995   \n",
       "1  [['Chama Cha Mapinduzi', 'PERSON'], ['Revoluti...         0.541939   \n",
       "2  [['Florida', 'GPE'], ['November 2018', 'DATE']...         0.234810   \n",
       "\n",
       "   bert_large_score                                   context_filename  \\\n",
       "0          0.601183  ['/root/Dataset/COSMOS/context/Context_EL/0_1....   \n",
       "1          0.729243  ['/root/Dataset/COSMOS/context/Context_EL/1_8....   \n",
       "2          0.307628  ['/root/Dataset/COSMOS/context/Context_EL/2_1....   \n",
       "\n",
       "                                             answers  \\\n",
       "0  [('lightweight” without the experience needed ...   \n",
       "1                                                 []   \n",
       "2  [('an army of internet trolls', \"53,000 dead p...   \n",
       "\n",
       "                                                 sim  \\\n",
       "0                           [0.06486875, 0.99999994]   \n",
       "1                                                 []   \n",
       "2  [0.025132587, 0.07283948, 0.026980357, 0.10170...   \n",
       "\n",
       "                             pred final_pred  \n",
       "0                   [True, False]        NaN  \n",
       "1                              []        NaN  \n",
       "2  [True, True, True, True, True]       True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('./df_answer_EL.csv')\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/NLP/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1248: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at binwang/bert-base-nli-stsb and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1000/1000 [02:52<00:00,  5.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from sbert import sbert\n",
    "\n",
    "def sim(row):\n",
    "    return [sbert(sentences) for sentences in eval(row.answers) if len(sentences) == 2 ]\n",
    "\n",
    "test_data['sim'] = test_data.progress_apply(sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(row, thresh):\n",
    "    pred = [i < thresh for i in row.sim]\n",
    "    return pred\n",
    "\n",
    "def get_mode(row):\n",
    "    li = row.pred\n",
    "    if li == []:\n",
    "        return 0\n",
    "    # li = infer(li)\n",
    "    val, count = np.unique(li, return_counts=True)\n",
    "\n",
    "    if len(count) == 2 and count[0] == count[1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return val[np.argmax(count)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 48853.91it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 27970.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "prec, recall, acc = [], [], []\n",
    "\n",
    "\n",
    "thresh = 0.4\n",
    "test_data['pred'] = test_data.progress_apply(lambda row: infer(row, thresh), axis=1)\n",
    "test_data['final_pred'] = test_data.progress_apply(get_mode, axis=1)\n",
    "\n",
    "pred = list(test_data['final_pred'])\n",
    "\n",
    "ground_truth = list(test_data['context_label'])\n",
    "for i, x in enumerate(pred):\n",
    "    if x is None:\n",
    "        print(\"HAHA\")\n",
    "        pred[i] = test_data.iloc[i].bert_base_score < 0.5\n",
    "prec.append(precision_score(ground_truth, pred))\n",
    "recall.append(recall_score(ground_truth, pred))\n",
    "acc.append(accuracy_score(ground_truth, pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.597]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "848ec3303aa6c64d107256817a16d6a039fa8cfd0fa250d143bf87759298d876"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
